model:
  name: qwen3-0.6b
  hidden_size: 1024
  num_layers: 24
  num_heads: 16
  head_dim: 64
  vocab_size: 151936
precision: bf16
rms_eps: 1.0e-6
rope_theta: 10000.0
kv_layout: 0
kv_quant: null
persistent: false
persistent_blocks: 4
threads_per_block: 256
kernel:
  num_blocks: 0
  threads_per_block: 0
  role_split:
    qkv: 0
    attn: 0
    mlp: 0
    prefetch: 0
  prefetch_depth: 0
